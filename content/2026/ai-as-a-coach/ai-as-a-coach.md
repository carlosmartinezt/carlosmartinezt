---
title: 'AI as a Coach'
description: "AI is becoming part of how we build software. It helps us write code faster, explore ideas more quickly, and try things we wouldn't have attempted before. That's real progress. But using AI more is not the same as doing better work."
pubDate: '2026-01-16'
author: 'Carlos Martinez Tuanama'
tags: [ai, thinking]
---

## âš ï¸ We're using AI more, and that's the wrong thing to optimize

AI is becoming part of how we build software. It helps us write code faster, explore ideas more quickly, and try things we wouldn't have attempted before. That's real progress. But **using AI more is not the same as doing better work.**

Optimizing for AI usage is the wrong metric. It's like optimizing for typing more lines of code. Tools are not the goal. Better judgment, clearer decisions, and higher-quality outcomes are.

Things are also moving very fast. New models, new workflows, new expectations. It's easy to feel like you're falling behind if you don't keep up. When expectations are unclear, we default to what's visible: speed. More output. Faster iteration. That pressure is real, and it's understandable.

> The risk is subtle. Efficiency quietly becomes shorthand for speed, and speed becomes a way to outsource thinking.

![blog placeholder](./using-ai-more-is-not-the-same-as-doing-better-work.jpg)

## ðŸ§  A better mental model: AI as a coach for your thinking

A more useful way to think about AI is as a **coach**, not a shortcut. A good coach doesn't do the work for you. They:

- Ask questions
- Challenge assumptions
- Push you to explain your reasoning

Used well, AI does the same. It helps you see blind spots, test ideas, and sharpen your judgment. The responsibility stays with you. You still need to understand what you're building and why it works.

This applies to code just as much as anything else. AI is powerful when it helps you reason about tradeoffs, edge cases, system behavior, and failure modes. Not just when it generates code quickly.

## âœ… Quality first, speed as a side effect

Strong judgment should come first. When quality is high, speed often follows as a side effect. When speed comes at the cost of clarity and rigor, it's worth questioning.

A simple test applies to any AI-assisted work:

> If you can't clearly explain it in your own words, you don't fully own it yet. That's not failure. It's a signal that more thinking will pay off.

The question I keep coming back to is simple: **is AI helping me think better, or just faster?** If we optimize for better thinking instead of visible AI usage, the efficiency we care about will follow.

![blog placeholder](./image2.jpg)

## ðŸ’Ž Core idea I want to carry forward

What I ultimately care about is **clarity of thinking**.

Clear thinking means being able to articulate:

- What you're concerned about
- Why it matters
- What tradeoffs you're making

When thinking is unclear, everything downstream suffers: code quality, decisions, communication, and execution. When thinking is clear, the rest becomes easier.

For me, AI has been most valuable as a way to reach that clarity over the past few weeks. Not by giving answers, but by helping structure thoughts, surface assumptions, and force articulation.

> Once clarity of thinking is achieved, speed, efficiency, and execution tend to follow naturally. **Clarity is the real leverage point.**

> **2/1/26 Update:** Oh, how wrong I was. The best model so far is Claude Opus 4.5. What a difference!


![blog placeholder](./image3.jpg)
![blog placeholder](./image4.jpg)
![blog placeholder](./image5.jpg)
